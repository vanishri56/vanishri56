{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6rko_ANX0EC"
      },
      "source": [
        "# Document Summarization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OS0BZao8mkWv"
      },
      "source": [
        "\n",
        "This notebook demonstrates an application of long document summarization techniques to a work of literature using Granite."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Nvl1Ip1mkWx"
      },
      "source": [
        "### Python version"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUIasEz1mkWz"
      },
      "source": [
        "Ensure you are running python 3.10, 3.11, or 3.12 in a freshly-created virtual environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "wh5HUi8pmkW1"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "assert sys.version_info >= (3, 10) and sys.version_info < (3, 13), \"Use Python 3.10, 3.11, or 3.12 to run this notebook.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwS1CzAbaFzq"
      },
      "source": [
        "## Install Dependencies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFyAg06emkW3"
      },
      "source": [
        "\n",
        "Granite utils provides some helpful functions for recipes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "2zUHQD71qgqf",
        "outputId": "ee1935f1-707d-44a3-8412-157a8e24a004",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/ibm-granite-community/utils\n",
            "  Cloning https://github.com/ibm-granite-community/utils to /tmp/pip-req-build-gte_raon\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/ibm-granite-community/utils /tmp/pip-req-build-gte_raon\n",
            "  Resolved https://github.com/ibm-granite-community/utils to commit c9a6b769ec5f436629cecf649afcd8f130908c30\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.11/dist-packages (0.3.25)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\n",
            "Requirement already satisfied: langchain_huggingface in /usr/local/lib/python3.11/dist-packages (0.3.0)\n",
            "Requirement already satisfied: langchain_ollama in /usr/local/lib/python3.11/dist-packages (0.3.3)\n",
            "Requirement already satisfied: replicate in /usr/local/lib/python3.11/dist-packages (1.0.7)\n",
            "Requirement already satisfied: docling in /usr/local/lib/python3.11/dist-packages (2.36.1)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (from ibm-granite-community-utils==0.1.dev66) (1.1.0)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.65 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.65)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.25 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.25)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.41)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (9.1.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.9.1)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.45)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.4.0)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.32.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: ollama<1.0.0,>=0.4.8 in /usr/local/lib/python3.11/dist-packages (from langchain_ollama) (0.5.1)\n",
            "Requirement already satisfied: httpx<1,>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from replicate) (0.28.1)\n",
            "Requirement already satisfied: pydantic>1.10.7 in /usr/local/lib/python3.11/dist-packages (from replicate) (2.11.5)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from replicate) (4.14.0)\n",
            "Requirement already satisfied: docling-core<3.0.0,>=2.29.0 in /usr/local/lib/python3.11/dist-packages (from docling-core[chunking]<3.0.0,>=2.29.0->docling) (2.34.2)\n",
            "Requirement already satisfied: docling-ibm-models<4.0.0,>=3.4.4 in /usr/local/lib/python3.11/dist-packages (from docling) (3.4.4)\n",
            "Requirement already satisfied: docling-parse<5.0.0,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from docling) (4.0.4)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from docling) (1.2.0)\n",
            "Requirement already satisfied: pypdfium2<5.0.0,>=4.30.0 in /usr/local/lib/python3.11/dist-packages (from docling) (4.30.1)\n",
            "Requirement already satisfied: easyocr<2.0,>=1.7 in /usr/local/lib/python3.11/dist-packages (from docling) (1.7.2)\n",
            "Requirement already satisfied: certifi>=2024.7.4 in /usr/local/lib/python3.11/dist-packages (from docling) (2025.4.26)\n",
            "Requirement already satisfied: rtree<2.0.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from docling) (1.4.0)\n",
            "Requirement already satisfied: typer<0.17.0,>=0.12.5 in /usr/local/lib/python3.11/dist-packages (from docling) (0.16.0)\n",
            "Requirement already satisfied: python-docx<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from docling) (1.1.2)\n",
            "Requirement already satisfied: python-pptx<2.0.0,>=1.0.2 in /usr/local/lib/python3.11/dist-packages (from docling) (1.0.2)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.11/dist-packages (from docling) (4.13.4)\n",
            "Requirement already satisfied: pandas<3.0.0,>=2.1.4 in /usr/local/lib/python3.11/dist-packages (from docling) (2.2.2)\n",
            "Requirement already satisfied: marko<3.0.0,>=2.1.2 in /usr/local/lib/python3.11/dist-packages (from docling) (2.1.3)\n",
            "Requirement already satisfied: openpyxl<4.0.0,>=3.1.5 in /usr/local/lib/python3.11/dist-packages (from docling) (3.1.5)\n",
            "Requirement already satisfied: lxml<6.0.0,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from docling) (5.4.0)\n",
            "Requirement already satisfied: pillow<12.0.0,>=10.0.0 in /usr/local/lib/python3.11/dist-packages (from docling) (11.2.1)\n",
            "Requirement already satisfied: pluggy<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from docling) (1.6.0)\n",
            "Requirement already satisfied: pylatexenc<3.0,>=2.10 in /usr/local/lib/python3.11/dist-packages (from docling) (2.10)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from docling) (1.15.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->docling) (2.7)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.16.0 in /usr/local/lib/python3.11/dist-packages (from docling-core<3.0.0,>=2.29.0->docling-core[chunking]<3.0.0,>=2.29.0->docling) (4.24.0)\n",
            "Requirement already satisfied: jsonref<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from docling-core<3.0.0,>=2.29.0->docling-core[chunking]<3.0.0,>=2.29.0->docling) (1.1.0)\n",
            "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from docling-core<3.0.0,>=2.29.0->docling-core[chunking]<3.0.0,>=2.29.0->docling) (0.9.0)\n",
            "Requirement already satisfied: latex2mathml<4.0.0,>=3.77.0 in /usr/local/lib/python3.11/dist-packages (from docling-core<3.0.0,>=2.29.0->docling-core[chunking]<3.0.0,>=2.29.0->docling) (3.78.0)\n",
            "Requirement already satisfied: semchunk<3.0.0,>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from docling-core[chunking]<3.0.0,>=2.29.0->docling) (2.2.2)\n",
            "Requirement already satisfied: torch<3.0.0,>=2.2.2 in /usr/local/lib/python3.11/dist-packages (from docling-ibm-models<4.0.0,>=3.4.4->docling) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision<1,>=0 in /usr/local/lib/python3.11/dist-packages (from docling-ibm-models<4.0.0,>=3.4.4->docling) (0.21.0+cu124)\n",
            "Requirement already satisfied: jsonlines<4.0.0,>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from docling-ibm-models<4.0.0,>=3.4.4->docling) (3.1.0)\n",
            "Requirement already satisfied: opencv-python-headless<5.0.0.0,>=4.6.0.66 in /usr/local/lib/python3.11/dist-packages (from docling-ibm-models<4.0.0,>=3.4.4->docling) (4.11.0.86)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from easyocr<2.0,>=1.7->docling) (0.25.2)\n",
            "Requirement already satisfied: python-bidi in /usr/local/lib/python3.11/dist-packages (from easyocr<2.0,>=1.7->docling) (0.6.6)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.11/dist-packages (from easyocr<2.0,>=1.7->docling) (2.1.1)\n",
            "Requirement already satisfied: pyclipper in /usr/local/lib/python3.11/dist-packages (from easyocr<2.0,>=1.7->docling) (1.3.0.post6)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.11/dist-packages (from easyocr<2.0,>=1.7->docling) (1.11.1.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.21.0->replicate) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.21.0->replicate) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.21.0->replicate) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.21.0->replicate) (0.16.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.2)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.25->langchain_community) (0.3.8)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.65->langchain_community) (1.33)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.23.0)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl<4.0.0,>=3.1.5->docling) (2.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0.0,>=2.1.4->docling) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0.0,>=2.1.4->docling) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0.0,>=2.1.4->docling) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>1.10.7->replicate) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>1.10.7->replicate) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>1.10.7->replicate) (0.4.1)\n",
            "Requirement already satisfied: XlsxWriter>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from python-pptx<2.0.0,>=1.0.2->docling) (3.2.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2.4.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.2.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<0.17.0,>=0.12.5->docling) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<0.17.0,>=0.12.5->docling) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<0.17.0,>=0.12.5->docling) (13.9.4)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.65->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.16.0->docling-core<3.0.0,>=2.29.0->docling-core[chunking]<3.0.0,>=2.29.0->docling) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.16.0->docling-core<3.0.0,>=2.29.0->docling-core[chunking]<3.0.0,>=2.29.0->docling) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.16.0->docling-core<3.0.0,>=2.29.0->docling-core[chunking]<3.0.0,>=2.29.0->docling) (0.25.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0.0,>=2.1.4->docling) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<0.17.0,>=0.12.5->docling) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<0.17.0,>=0.12.5->docling) (2.19.1)\n",
            "Requirement already satisfied: mpire[dill] in /usr/local/lib/python3.11/dist-packages (from semchunk<3.0.0,>=2.2.0->docling-core[chunking]<3.0.0,>=2.29.0->docling) (2.10.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.4.4->docling) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.4.4->docling) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.4.4->docling) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.4.4->docling) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.4.4->docling) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.4.4->docling) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.4.4->docling) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.4.4->docling) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.4.4->docling) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.4.4->docling) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.4.4->docling) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.4.4->docling) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.4.4->docling) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.4.4->docling) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.4.4->docling) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.4.4->docling) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.4.4->docling) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.4.4->docling) (1.3.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.1.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.21.0->replicate) (1.3.1)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image->easyocr<2.0,>=1.7->docling) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image->easyocr<2.0,>=1.7->docling) (2025.6.1)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->easyocr<2.0,>=1.7->docling) (0.4)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<0.17.0,>=0.12.5->docling) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.4.4->docling) (3.0.2)\n",
            "Requirement already satisfied: multiprocess>=0.70.15 in /usr/local/lib/python3.11/dist-packages (from mpire[dill]->semchunk<3.0.0,>=2.2.0->docling-core[chunking]<3.0.0,>=2.29.0->docling) (0.70.15)\n",
            "Requirement already satisfied: dill>=0.3.7 in /usr/local/lib/python3.11/dist-packages (from multiprocess>=0.70.15->mpire[dill]->semchunk<3.0.0,>=2.2.0->docling-core[chunking]<3.0.0,>=2.29.0->docling) (0.3.7)\n"
          ]
        }
      ],
      "source": [
        "! pip install git+https://github.com/ibm-granite-community/utils \\\n",
        "    langchain_community \\\n",
        "    transformers \\\n",
        "    langchain_huggingface \\\n",
        "    langchain_ollama \\\n",
        "    replicate \\\n",
        "    docling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QpQT_N_mkW5"
      },
      "source": [
        "## Serving the Granite AI model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cIz-kj8hmkW7"
      },
      "source": [
        "\n",
        "This notebook requires IBM Granite models to be served by an AI model runtime so that the models can be invoked or called. This notebook can use a locally accessible [Ollama](https://github.com/ollama/ollama) server to serve the models, or the [Replicate](https://replicate.com) cloud service.\n",
        "\n",
        "During the pre-work, you may have either started a local Ollama server on your computer, or setup Replicate access and obtained an [API token](https://replicate.com/account/api-tokens)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydrVWz7EYHh9"
      },
      "source": [
        "## Select your model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7dDA6rjmkW9"
      },
      "source": [
        "Select a Granite model to use. Here we use a Langchain client to connect to the model. If there is a locally accessible Ollama server, we use an Ollama client to access the model. Otherwise, we use a Replicate client to access the model.\n",
        "\n",
        "When using Replicate, if the `REPLICATE_API_TOKEN` environment variable is not set, or a `REPLICATE_API_TOKEN` Colab secret is not set, then the notebook will ask for your [Replicate API token](https://replicate.com/account/api-tokens) in a dialog box."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "TSkiGBY4qo32"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "from langchain_ollama.llms import OllamaLLM\n",
        "from langchain_community.llms import Replicate\n",
        "from ibm_granite_community.notebook_utils import get_env_var\n",
        "\n",
        "model_path = \"ibm-granite/granite-3.3-8b-instruct\"\n",
        "try: # Look for a locally accessible Ollama server for the model\n",
        "    response = requests.get(os.getenv(\"OLLAMA_HOST\", \"http://127.0.0.1:11434\"))\n",
        "    model = OllamaLLM(\n",
        "        model=\"granite3.3:8b\",\n",
        "        num_ctx=65536, # 64K context window\n",
        "    )\n",
        "    model = model.bind(raw=True) # Client side controls prompt\n",
        "except Exception: # Use Replicate for the model\n",
        "    model = Replicate(\n",
        "        model=model_path,\n",
        "        replicate_api_token=get_env_var('REPLICATE_API_TOKEN'),\n",
        "        model_kwargs={\n",
        "            \"max_tokens\": 2000, # Set the maximum number of tokens to generate as output.\n",
        "            \"min_tokens\": 200, # Set the minimum number of tokens to generate as output.\n",
        "            \"temperature\": 0.75,\n",
        "            \"presence_penalty\": 0,\n",
        "            \"frequency_penalty\": 0,\n",
        "        },\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5d0sWaZ7YLHN"
      },
      "source": [
        "## Split a book into chunks\n",
        "\n",
        "The code in the following sections will fetch H.D. Thoreau's \"Walden\" from [Project Gutenberg](https://www.gutenberg.org/) for summarization.\n",
        "\n",
        "We will then chunk the book text so that chunks fit in the context window size of the AI model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYuQmgRJY0n5"
      },
      "source": [
        "### Count the tokens\n",
        "\n",
        "Before sending our book chunks to the AI model, it's crucial to understand how much of the model's capacity we're using. Language models typically have a limit on the number of tokens they can process in a single request.\n",
        "\n",
        "Key points:\n",
        "- We're using the [`granite-3.3`](https://huggingface.co/ibm-granite/granite-3.3-2b-instruct) model, which has a context window of 128K tokens.\n",
        "- Tokenization can vary between models, so we use the specific tokenizer for our chosen model.\n",
        "\n",
        "Understanding token count helps us optimize our prompts and ensure we're using the model efficiently."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "7JqmvTqbWPgl"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhTvIu5MmkW_"
      },
      "source": [
        "### Summary of Summaries\n",
        "\n",
        "Here we use a hierarchical abstractive summarization technique to adapt to the context length of the model. Our approach uses [Docling](https://docling-project.github.io/docling/) to understand the document's structure, chunk the document into text passages, and group the text passages by chapter which we can then summarize."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "oS08SLwOmkW_",
        "outputId": "a09e6858-5c10-4ac2-fb90-78eeee3710de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18 documents created\n",
            "Max document size: 38299 tokens\n"
          ]
        }
      ],
      "source": [
        "import itertools\n",
        "from typing import Iterator, Callable\n",
        "from docling.document_converter import DocumentConverter\n",
        "from docling_core.transforms.chunker.hierarchical_chunker import HierarchicalChunker\n",
        "from docling_core.transforms.chunker.base import BaseChunk\n",
        "\n",
        "def chunk_document(source: str, *, dropwhile: Callable[[BaseChunk], bool] = lambda c: False, takewhile: Callable[[BaseChunk], bool] = lambda c: True) -> Iterator[BaseChunk]:\n",
        "    \"\"\"Read the document and perform a hierarchical chunking\"\"\"\n",
        "    converter = DocumentConverter()\n",
        "    chunks = HierarchicalChunker().chunk(converter.convert(source=source).document)\n",
        "    return itertools.takewhile(takewhile, itertools.dropwhile(dropwhile, chunks))\n",
        "\n",
        "def merge_chunks(chunks: Iterator[BaseChunk], *, headings: Callable[[BaseChunk], list[str]] = lambda c: c.meta.headings) -> Iterator[dict[str, str]]:\n",
        "    \"\"\"Merge chunks having the same headings\"\"\"\n",
        "    prior_headings: list[str] | None = None\n",
        "    document: dict[str, str] = {}\n",
        "    doc_id = 0\n",
        "    for chunk in chunks:\n",
        "        text = chunk.text.replace('\\r\\n', '\\n')\n",
        "        current_headings = headings(chunk)\n",
        "        if prior_headings != current_headings:\n",
        "            if document:\n",
        "                yield document\n",
        "            prior_headings = current_headings\n",
        "            document = {\n",
        "                'doc_id': str(doc_id := doc_id + 1),\n",
        "                'title': \" - \".join(current_headings),\n",
        "                'text': text\n",
        "            }\n",
        "        else:\n",
        "            document['text'] += f\"\\n\\n{text}\"\n",
        "    if document:\n",
        "        yield document\n",
        "\n",
        "def chunk_dropwhile(chunk: BaseChunk) -> bool:\n",
        "    \"\"\"Ignore front matter prior to the book start\"\"\"\n",
        "    return \"WALDEN\" not in chunk.meta.headings\n",
        "\n",
        "def chunk_takewhile(chunk: BaseChunk) -> bool:\n",
        "    \"\"\"Ignore remaining chunks once we see this heading\"\"\"\n",
        "    return \"ON THE DUTY OF CIVIL DISOBEDIENCE\" not in chunk.meta.headings\n",
        "\n",
        "def chunk_headings(chunk: BaseChunk) -> list[str]:\n",
        "    \"\"\"Use the h1 and h2 (chapter) headings\"\"\"\n",
        "    return chunk.meta.headings[:2]\n",
        "\n",
        "documents: list[dict[str, str]] = list(merge_chunks(\n",
        "    chunk_document(\n",
        "        \"https://www.gutenberg.org/cache/epub/205/pg205-images.html\",\n",
        "        dropwhile=chunk_dropwhile,\n",
        "        takewhile=chunk_takewhile,\n",
        "    ),\n",
        "    headings=chunk_headings,\n",
        "))\n",
        "\n",
        "print(f\"{len(documents)} documents created\")\n",
        "print(f\"Max document size: {max(len(tokenizer.tokenize(document['text'])) for document in documents)} tokens\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ym_rZSSHmkXA"
      },
      "source": [
        "## Summarize the chunks\n",
        "\n",
        "Here we define a method to generate a response using a list of documents and a user prompt about those documents.\n",
        "\n",
        "We create the prompt according to the [Granite Prompting Guide](https://www.ibm.com/granite/docs/models/granite/#chat-template) and provide the documents using the `documents` parameter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "4DGWr5dXmkXB"
      },
      "outputs": [],
      "source": [
        "def generate(user_prompt: str, documents: list[dict[str, str]]):\n",
        "    \"\"\"Use the chat template to format the prompt\"\"\"\n",
        "    prompt = tokenizer.apply_chat_template(\n",
        "        conversation=[{\n",
        "            \"role\": \"user\",\n",
        "            \"content\": user_prompt,\n",
        "        }],\n",
        "        documents=documents, # This uses the documents support in the Granite chat template\n",
        "        add_generation_prompt=True,\n",
        "        tokenize=False,\n",
        "    )\n",
        "\n",
        "    print(f\"Input size: {len(tokenizer.tokenize(prompt))} tokens\")\n",
        "    output = model.invoke(prompt)\n",
        "    print(f\"Output size: {len(tokenizer.tokenize(output))} tokens\")\n",
        "\n",
        "    return output\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3FkSYf6mkXB"
      },
      "source": [
        "For each chapter, we create a separate summary. This can take a few minutes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "o9WBST1rmkXB",
        "outputId": "528de395-6273-40bb-b43a-48f84cad9003",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================= WALDEN - Economy (1/18) =============================\n",
            "Input size: 38447 tokens\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ReplicateError",
          "evalue": "ReplicateError Details:\ntitle: Unauthenticated\nstatus: 401\ndetail: You did not pass an authentication token",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mReplicateError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-799527592>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocument\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"============================= {document['title']} ({i+1}/{len(documents)}) =============================\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_prompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     summaries.append({\n\u001b[1;32m     14\u001b[0m         \u001b[0;34m'doc_id'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdocument\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'doc_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-40-934444851>\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(user_prompt, documents)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Input size: {len(tokenizer.tokenize(prompt))} tokens\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Output size: {len(tokenizer.tokenize(output))} tokens\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m         return (\n\u001b[0;32m--> 389\u001b[0;31m             self.generate_prompt(\n\u001b[0m\u001b[1;32m    390\u001b[0m                 \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m                 \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36mgenerate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    764\u001b[0m     ) -> LLMResult:\n\u001b[1;32m    765\u001b[0m         \u001b[0mprompt_strings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 766\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_strings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    767\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverride\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    971\u001b[0m                 )\n\u001b[1;32m    972\u001b[0m             ]\n\u001b[0;32m--> 973\u001b[0;31m             return self._generate_helper(\n\u001b[0m\u001b[1;32m    974\u001b[0m                 \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m                 \u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36m_generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             output = (\n\u001b[0;32m--> 792\u001b[0;31m                 self._generate(\n\u001b[0m\u001b[1;32m    793\u001b[0m                     \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m                     \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1545\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprompt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1546\u001b[0m             text = (\n\u001b[0;32m-> 1547\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1548\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1549\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_community/llms/replicate.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, prompt, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    139\u001b[0m                     \u001b[0mcompletion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m             \u001b[0mprediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"failed\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_community/llms/replicate.py\u001b[0m in \u001b[0;36m_create_prediction\u001b[0;34m(self, prompt, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mversion_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m                 \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreplicate_python\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_version\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/replicate/model.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_model_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"GET\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_json_to_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_client\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/replicate/client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, method, path, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mhttpx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0m_raise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/replicate/client.py\u001b[0m in \u001b[0;36m_raise_for_status\u001b[0;34m(resp)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_raise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mhttpx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;36m400\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m600\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mReplicateError\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mReplicateError\u001b[0m: ReplicateError Details:\ntitle: Unauthenticated\nstatus: 401\ndetail: You did not pass an authentication token"
          ]
        }
      ],
      "source": [
        "if get_env_var('GRANITE_TESTING', 'false').lower() == 'true':\n",
        "    documents = documents[:5] # shorten testing work\n",
        "\n",
        "user_prompt = \"\"\"\\\n",
        "Using only the the book chapter document, compose a summary of the book chapter.\n",
        "Your response should only include the summary. Do not provide any further explanation.\"\"\"\n",
        "\n",
        "summaries: list[dict[str, str]] = []\n",
        "\n",
        "for i, document in enumerate(documents):\n",
        "    print(f\"============================= {document['title']} ({i+1}/{len(documents)}) =============================\")\n",
        "    output = generate(user_prompt, [document])\n",
        "    summaries.append({\n",
        "        'doc_id': document['doc_id'],\n",
        "        'title': document['title'],\n",
        "        'text': output,\n",
        "    })\n",
        "\n",
        "print(\"Summary count: \" + str(len(summaries)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWbDtXjsmkXD"
      },
      "source": [
        "## Create the Final Summary\n",
        "\n",
        "Now we need to summarize the chapter summaries. We prompt the model to create a unified summary of the chapter summaries we previously generated."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5xWcl-jKmkXD"
      },
      "outputs": [],
      "source": [
        "from ibm_granite_community.notebook_utils import wrap_text\n",
        "\n",
        "user_prompt = \"\"\"\\\n",
        "Using only the book chapter summary documents, compose a single, unified summary of the book.\n",
        "Your response should only include the unified summary. Do not provide any further explanation.\"\"\"\n",
        "\n",
        "output = generate(user_prompt, summaries)\n",
        "print(wrap_text(output))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8fU7pximkXE"
      },
      "source": [
        "So we have now summarized a document larger than the AI model's context window length by breaking the document down into smaller pieces to summarize and then summarizing those summaries."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}